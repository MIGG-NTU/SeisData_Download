{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Seismic Data Processing\n",
    "\n",
    "This tutorial aims to introduce some basic seismic data processing steps.\n",
    "\n",
    "**Authors**\n",
    "\n",
    "- Shijie Hao ([HouseJaay](https://github.com/HouseJaay))\n",
    "- Jiayuan Yao ([core-man](https://github.com/core-man))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preparation\n",
    "\n",
    "We first use [ObsPy mass_downloader](https://docs.obspy.org/packages/autogen/obspy.clients.fdsn.mass_downloader.html) to download seismic data recorded at seismic stations in a box region for the [Ridgecreat earthquake](https://earthquake.usgs.gov/earthquakes/eventpage/ci38457511/executive) sequence.\n",
    "\n",
    "To save time, we only use three largest ones, including the main shock, a foreshock and a aftershock. Actually, this catalog is just the exercise last week."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction\n",
    "\n",
    "After we download raw seismic time series data from data centers, we usually perform some basic data processing before further data analysis.\n",
    "\n",
    "There are several basic data processing steps which are commonly performed in the daily research.\n",
    "\n",
    "- [SAC Chinese Documention](https://seisman.github.io/SAC_Docs_zh/data-process/)\n",
    "- [ObsPy Tutorial](https://docs.obspy.org/master/tutorial/index.html)\n",
    "- [Live Jupyter Notebooks for Seismology](https://krischer.github.io/seismo_live_build/tree/index.html)\n",
    "- [Remote Online Sessions for Emerging Seismologists: ObsPy](https://www.iris.edu/hq/inclass/course/roses)\n",
    "\n",
    "\n",
    "In this tutorial, we only introduce some of them indicated below, which must be performed in our seismic tomographic studies, while other data processing may be needed in your own studies.\n",
    "\n",
    "- Time series data format conversion\n",
    "- Data merging\n",
    "- Data file renaming\n",
    "- Adding event and station metadata\n",
    "- Filtering\n",
    "\n",
    "While we use ObsPy to present data processing here, you are encouraged to refer to [SAC Chinese Documentation](https://seisman.github.io/SAC_Docs_zh/call-in-script/) to learn how to call SAC in Python/bash/Perl to perform the same processing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "from obspy import UTCDateTime\n",
    "import obspy\n",
    "import obspy.io.sac.sactrace\n",
    "from obspy.taup import TauPyModel\n",
    "from distaz import DistAz\n",
    "import os\n",
    "import glob"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define some tool functions\n",
    "\n",
    "You can define your own tools functions according to your data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read event metadata\n",
    "\n",
    "The used earthquake catalog is a csv file. We may use [csv module](https://docs.python.org/3/library/csv.html) to simplify the code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_evt(evtf):\n",
    "    \"\"\"\n",
    "    read event information\n",
    "    \"\"\"\n",
    "    with open(evtf, 'r') as f:\n",
    "        lines = f.readlines()[1:]\n",
    "    events = []\n",
    "    dnames = []\n",
    "    for line in lines:\n",
    "        line = line.strip()\n",
    "        temp = line.split(',')\n",
    "        t = UTCDateTime(temp[0])\n",
    "        lat, lon = float(temp[1]), float(temp[2])\n",
    "        depth = float(temp[3])\n",
    "        dpu = temp[4]\n",
    "        mag = float(temp[5])\n",
    "        magt = temp[6]\n",
    "        events.append([t, lat, lon, depth, dpu, mag, magt])\n",
    "        dnames.append(\"%04d%02d%02d%02d%02d%02d%s\" % (t.year, t.month, t.day, t.hour, t.minute, t.second, str(t.microsecond)[:3]))\n",
    "    return dnames, events"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read station metadata\n",
    "\n",
    "The used station metadata is a custom file. We may revise the code to use other format.\n",
    "\n",
    "**Note** that the dip of an instrument in SOD and ObsPy are a little different from that defined in SAC."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_sta(staf):\n",
    "    \"\"\"\n",
    "    read station information\n",
    "    \"\"\"\n",
    "    with open(staf, 'r') as f:\n",
    "        lines = f.readlines()\n",
    "    stations, name = [], []\n",
    "    for line in lines:\n",
    "        line=line.strip()\n",
    "        #if (not line) or line[0] == '#':\n",
    "        #    continue\n",
    "\n",
    "        #temp = line.split(' ')\n",
    "        temp = line.split('|')\n",
    "        name.append(temp[0])\n",
    "        stla, stlo, stel, azimuth, dip = float(temp[1]), float(temp[2]), float(temp[3].split()[0]), float(temp[5]), float(temp[6])\n",
    "        stations.append([stla, stlo, stel, azimuth, dip])\n",
    "    return name, stations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data pre-processing\n",
    "\n",
    "Some data pre-processing have to be performed, since the downloaded time series data are miniseed.\n",
    "\n",
    "- Time series data format conversion:\n",
    "    - `Waveform Import/Export Plug-ins` in [ObsPy](https://docs.obspy.org/master/packages/index.html): e.g., [Python interface to SAC](https://docs.obspy.org/packages/autogen/obspy.io.sac.sactrace.html) ([SACTrace class](https://docs.obspy.org/packages/autogen/obspy.io.sac.sactrace.SACTrace.html))\n",
    "    - [rdseed](https://seisman.github.io/SAC_Docs_zh/data-process/data-format/)\n",
    "    - [mseed2sac](https://ds.iris.edu/ds/nodes/dmc/software/downloads/mseed2sac/)\n",
    "    - [sac2tol](https://github.com/core-man/SACtools#sac2col)\n",
    "    \n",
    "- `merge`: [ObsPy](https://docs.obspy.org/packages/autogen/obspy.core.stream.Stream.merge.html) | [SAC](https://seisman.github.io/SAC_Docs_zh/data-process/merge-traces/)\n",
    "\n",
    "- Data file renmaing: [SAC](https://seisman.github.io/SAC_Docs_zh/data-process/rename/)\n",
    "\n",
    "- Adding event and station metadata:\n",
    "    - [obspy.io.sac](https://docs.obspy.org/master/packages/obspy.io.sac.html) | [Python interface to SAC](https://docs.obspy.org/packages/autogen/obspy.io.sac.sactrace.html) ([SACTrace class](https://docs.obspy.org/packages/autogen/obspy.io.sac.sactrace.SACTrace.html))\n",
    "    - SAC: [event](https://seisman.github.io/SAC_Docs_zh/data-process/event-info/) | [station](https://seisman.github.io/SAC_Docs_zh/data-process/station-info/)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mseed2sac(data_root, data_out, dnames, events, fnames, stations):\n",
    "    \"\"\"\n",
    "    convert miniseed to SAC\n",
    "    \"\"\"\n",
    "    \n",
    "    for evt in zip(dnames, events):\n",
    "        # output dir\n",
    "        outd = os.path.join(data_out, evt[0])\n",
    "        if not os.path.exists(outd):\n",
    "            os.makedirs(outd)\n",
    "\n",
    "        for sta in zip(fnames, stations):\n",
    "            # read miniseed\n",
    "            fpath = os.path.join(data_root, evt[0], sta[0] + '.mseed')\n",
    "            try:\n",
    "                st = obspy.read(fpath)\n",
    "            except FileNotFoundError:\n",
    "                #print(\"Missing File: %s\" % fpath)\n",
    "                continue\n",
    "\n",
    "            # merge multiple traces\n",
    "            st.merge(method=1, fill_value=0, interpolation_samples=-1)\n",
    "            \n",
    "            # convert to SACTrace from ObsPy Trace\n",
    "            sactr = obspy.io.sac.SACTrace.from_obspy_trace(st[0])\n",
    "            \n",
    "            # set event origin time as SAC reference time\n",
    "            sactr.reftime = evt[1][0]\n",
    "            sactr.o = 0\n",
    "            sactr.iztype = 'io'\n",
    "\n",
    "            # set station location\n",
    "            sactr.stla = sta[1][0]\n",
    "            sactr.stlo = sta[1][1]\n",
    "            sactr.stel = sta[1][2]\n",
    "            \n",
    "            # set event location and magnitude\n",
    "            sactr.evla = evt[1][1]\n",
    "            sactr.evlo = evt[1][2]\n",
    "            sactr.evdp = evt[1][3]\n",
    "            sactr.mag = evt[1][5]\n",
    "            \n",
    "            # set cmpaz and cmpinc\n",
    "            sactr.cmpaz = sta[1][3]\n",
    "            sactr.cmpinc = sta[1][4] + 90.0\n",
    "            \n",
    "            # other SAC headers\n",
    "            sactr.lcalda = 1  # DIST AZ BAZ and GCARC headers will be calculated from station and event coordinates.\n",
    "                              # Note that thing may not be same if we use ObsPy Trace.\n",
    "            \n",
    "            # write to sac files\n",
    "            sactr.write(os.path.join(outd, sta[0]+'.SAC'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Basic data processing\n",
    "\n",
    "Now we begin to perform some basic data processing. In this tutorial, we only do **`rmean` | `rtrend` | `taper`:** and `filtering`, while you can conduct other processing based on the references.\n",
    "\n",
    "\n",
    "**`rmean` | `rtrend` | `taper`:**\n",
    "\n",
    "- ObsPy: [detrend](https://docs.obspy.org/packages/autogen/obspy.core.stream.Stream.detrend.html) | [taper](https://docs.obspy.org/packages/autogen/obspy.core.stream.Stream.taper.html)\n",
    "- [SAC](https://seisman.github.io/SAC_Docs_zh/data-process/rmean-rtrend-taper/)\n",
    "\n",
    "**Remove instrument response:**\n",
    "\n",
    "- ObsPy: [remove_response](https://docs.obspy.org/packages/autogen/obspy.core.stream.Stream.remove_response.html) | [remove sensitivity](https://docs.obspy.org/packages/autogen/obspy.core.stream.Stream.remove_sensitivity.html)\n",
    "- [SAC](https://seisman.github.io/SAC_Docs_zh/data-process/instrument-response/)\n",
    "\n",
    "**Trim data:**\n",
    "\n",
    "- [ObsPy](https://docs.obspy.org/packages/autogen/obspy.core.stream.Stream.trim.html)\n",
    "- [SAC](https://seisman.github.io/SAC_Docs_zh/data-process/cut-data/)\n",
    "\n",
    "**Coordinate systerm rotation:**\n",
    "\n",
    "- [IRISWS roation](https://service.iris.edu/irisws/rotation/docs/1/help/)\n",
    "- ObsPy: [Stream.rotate](https://docs.obspy.org/packages/autogen/obspy.core.stream.Stream.rotate.html) | [obspy.singal.rotate](https://docs.obspy.org/packages/autogen/obspy.signal.rotate.html)\n",
    "- [SAC](https://seisman.github.io/SAC_Docs_zh/data-process/rotate/)\n",
    "\n",
    "**Resampling:**\n",
    "\n",
    "- ObsPy: [resample](https://docs.obspy.org/packages/autogen/obspy.core.stream.Stream.resample.html) | [decimate](https://docs.obspy.org/packages/autogen/obspy.core.stream.Stream.decimate.html) | [interpolate](https://docs.obspy.org/packages/autogen/obspy.core.stream.Stream.interpolate.html)\n",
    "- [SAC](https://seisman.github.io/SAC_Docs_zh/data-process/resampling/)\n",
    "\n",
    "**Filtering:**\n",
    "\n",
    "- [ObsPy](https://docs.obspy.org/packages/autogen/obspy.core.stream.Stream.filter.html)\n",
    "- [SAC](https://seisman.github.io/SAC_Docs_zh/data-process/filter/)\n",
    "\n",
    "\n",
    "**More methods can found be in ObsPy and SAC.**\n",
    "\n",
    "- ObsPy: [Stream](https://docs.obspy.org/packages/autogen/obspy.core.stream.Stream.html) | [Trace](https://docs.obspy.org/packages/autogen/obspy.core.trace.Trace.html) | [obspy.signal](https://docs.obspy.org/packages/obspy.signal.html)\n",
    "- [Chinse SAC documentation](https://seisman.github.io/SAC_Docs_zh/data-process/)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Rotate seismic time series data to different coordinate systems\n",
    "\n",
    "Sometimes, we have to use data in `RTZ` coordinate sysmtem instead of the original one, e.g., `NEZ` or `12Z`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "def do_rotate(data_dir):\n",
    "    \"\"\"\n",
    "    rotate data to RTZ coordinate system\n",
    "    \"\"\"\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Filter seismic time series data\n",
    "\n",
    "Bandpass seismic time series data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "def do_filter(data_dir, out_dir, freq_low, freq_high):\n",
    "    \"\"\"\n",
    "    filter data\n",
    "    \"\"\"\n",
    "    if not os.path.exists(out_dir):\n",
    "        os.mkdir(out_dir)\n",
    "\n",
    "    for ev in os.listdir(data_dir):\n",
    "        inpath = os.path.join(data_dir, ev)\n",
    "        outpath = os.path.join(out_dir, ev)\n",
    "        if not os.path.exists(outpath):\n",
    "            os.mkdir(outpath)\n",
    "\n",
    "        for sac in os.listdir(inpath):\n",
    "            insac = os.path.join(inpath, sac)\n",
    "            outsac = os.path.join(outpath, sac)\n",
    "            st = obspy.read(insac)\n",
    "\n",
    "            # rmean, rtrend & taper\n",
    "            st.detrend(\"demean\")\n",
    "            st.detrend(\"linear\")\n",
    "            st.taper(max_percentage=0.05, type='hann')\n",
    "            \n",
    "            # bandpass\n",
    "            st.filter('bandpass', freqmin=freq_low, freqmax=freq_high, corners=2)\n",
    "            \n",
    "            st[0].write(outsac, format='SAC')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data analysis\n",
    "\n",
    "In this tutorial, some data analyses are performed here for the convenience. However, you should decide when and where you should perform those data analyses."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Write theoretical arrival times\n",
    "\n",
    "Calculate theoretical arrival times and write to SAC headers.\n",
    "\n",
    "- [ObsPy](https://docs.obspy.org/packages/obspy.taup.html)\n",
    "- [SAC Chinese Documentation](https://seisman.github.io/SAC_Docs_zh/data-process/traveltime/)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "def theo_arrival(data_dir, model_name, phase):\n",
    "    \"\"\"\n",
    "    Write theoretical arrival times\n",
    "    \"\"\"\n",
    "    model = TauPyModel(model=model_name)\n",
    "\n",
    "    for ev in os.listdir(data_dir):\n",
    "        inpath = os.path.join(data_dir, ev)\n",
    "        #print(inpath)\n",
    "\n",
    "        for sacfile in glob.glob('{}/*.SAC'.format(inpath)):\n",
    "            #print(sacfile)\n",
    "\n",
    "            st = obspy.read(sacfile)\n",
    "            sachd = st[0].stats.sac\n",
    "            \n",
    "            # set P-wave first arrival\n",
    "            da = DistAz(sachd[\"stla\"], sachd[\"stlo\"], sachd[\"evla\"], sachd[\"evlo\"])\n",
    "            gcarc = da.getDelta()\n",
    "            arrivals = model.get_travel_times(source_depth_in_km=sachd[\"evdp\"],\n",
    "                                  distance_in_degree=gcarc, phase_list=[phase])\n",
    "            \n",
    "            sachd[\"t1\"] = arrivals[0].time + sachd[\"o\"]\n",
    "            sachd[\"kt1\"] = arrivals[0].name\n",
    "            \n",
    "            st[0].write(sacfile, format=\"SAC\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Begin to do data process\n",
    "\n",
    "Call the above functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dirs and files\n",
    "data_root = 'miniseed'                     # miniseed data dir\n",
    "data_sac = 'sac/raw'                       # raw sac data dir\n",
    "data_filt = 'sac/filt_1_4Hz'               # filtered sac data dir\n",
    "evt_lst = 'events.csv'                     # event metadata\n",
    "sta_lst = '../data-fetch/SOD/station.txt'  # station metadata\n",
    "\n",
    "if not os.path.exists(data_sac):\n",
    "    os.makedirs(data_sac)\n",
    "    \n",
    "# read event and station metadata\n",
    "dnames, events = read_evt(evt_lst)\n",
    "fnames, stations = read_sta(sta_lst)\n",
    "\n",
    "# convert miniseed to sac\n",
    "mseed2sac(data_root, data_sac, dnames, events, fnames, stations)\n",
    "\n",
    "# write theoretical arrival times\n",
    "theo_arrival(data_sac, \"ak135\", \"ttp\")\n",
    "\n",
    "# filter data\n",
    "do_filter(data_sac, data_filt, 1.0, 4.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
